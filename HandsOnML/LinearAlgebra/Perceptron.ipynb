{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector import Vector\n",
    "from line import Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: (Decimal('2'), Decimal('4'), Decimal('6'))\n"
     ]
    }
   ],
   "source": [
    "v1 = Vector([1,2,3])\n",
    "v2 = Vector([1,2,3])\n",
    "print(v1.plus(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Logic Unit (TLU) / Linear Threshold Unit(LTU)\n",
    "\n",
    "\n",
    "<img src=\"LTU.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---X---\n",
      "[[0.1 0.1 0.1]]\n",
      "---W---\n",
      "[[0.01]\n",
      " [0.01]\n",
      " [0.01]]\n",
      "---Weighted Sum Z---\n",
      "[[0.003]]\n",
      "---Output---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([  [0.1, 0.1, 0.1] ])\n",
    "W = np.array([  [0.01],[0.01], [0.01] ])\n",
    "\n",
    "print('---X---')\n",
    "print(X)\n",
    "print('---W---')\n",
    "print(W)\n",
    "\n",
    "def step_heaviside(z):\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print('---Weighted Sum Z---')\n",
    "z = np.dot(X,W)\n",
    "print(z)\n",
    "print('---Output---')\n",
    "output = step_heaviside(z)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 25  6  2]]\n",
      "[[ 3]\n",
      " [32]\n",
      " [19]\n",
      " [27]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = np.array([  [17,25,6,2] ])\n",
    "print(X)\n",
    "W = np.array([[3],[32], [19], [27]])\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1019]]\n"
     ]
    }
   ],
   "source": [
    "M = np.dot(X,W)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---X---\n",
      "[[1 1 1 1]\n",
      " [2 2 2 2]\n",
      " [3 3 3 3]]\n",
      "---W---\n",
      "[[1 2 3 4 5]\n",
      " [1 2 3 4 5]\n",
      " [1 2 3 4 5]\n",
      " [1 2 3 4 5]]\n",
      "Z\n",
      "[[ 4  8 12 16 20]\n",
      " [ 8 16 24 32 40]\n",
      " [12 24 36 48 60]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([ [1,1,1,1], [2,2,2,2], [3,3,3,3]] )\n",
    "w =  np.array([[1,2,3,4,5],[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5]])\n",
    "print('---X---')\n",
    "print(x)\n",
    "print('---W---')\n",
    "print(w)\n",
    "print('Z')\n",
    "dot = np.dot(x,w)\n",
    "print(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron\n",
    "<img src=\"perceptron.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---X---\n",
      "[[0.1 0.1]]\n",
      "---W---\n",
      "[[0.1 0.2 0.3]\n",
      " [0.1 0.2 0.3]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "As always, X represents the matrix of input features. \n",
    "It has one row per instance and one column per feature.\n",
    "\"\"\"\n",
    "X = np.array([ [0.1,0.1] ] )\n",
    "\"\"\"\n",
    "The weight matrix W contains all the connection weights except for the ones from the bias neuron.\n",
    "It has one row per input neuron and one column per artificial neuron in the layer.\n",
    "\"\"\"\n",
    "W =  np.array([  [0.1,0.2,0.3],[0.1,0.2,0.3] ])\n",
    "\n",
    "\"\"\"\n",
    "The bias vector b contains all the connection weights between the bias neuron and the artificial neurons.\n",
    "It has one bias term per artificial neuron\n",
    "\"\"\"\n",
    "b = 1\n",
    "\n",
    "\n",
    "print('---X---')\n",
    "print(X)\n",
    "print('---W---')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ø([[1.02 1.04 1.06]])\n"
     ]
    }
   ],
   "source": [
    "XW= np.dot(X,W)\n",
    "input_to_Activation_function = XW + b\n",
    "print(f'ø({input_to_Activation_function})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When The Artificial Neurons are TLU, the  activation function  is a step function (but this can accomodate other types of activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
