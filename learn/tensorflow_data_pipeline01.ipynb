{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202eff22",
   "metadata": {},
   "source": [
    "# tf.data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae351a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2420ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21,22,-108, 31, 1, 32,24,31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d58008",
   "metadata": {},
   "source": [
    "# Simple tf.data.Dataset object\n",
    "\n",
    "- **from_tensor_slices** creates a dataset with a separate element  for each row of the input tensor\n",
    "- **from_tensors** Combines the input and returns a dataset with a single element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cea3186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorDataset shapes: (8,), types: tf.int32>\n",
      "<TensorDataset shapes: (2, 8), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "# from tensors\n",
    "array1 = [21,22,-108, 31, 1, 32,24,31]\n",
    "from_tensors_dataset = tf.data.Dataset.from_tensors(array1)\n",
    "print(from_tensors_dataset)\n",
    "array2 = [[21,22,-108, 31, 1, 32,24,31],[21,22,-108, 31, 1, 32,24,31]]\n",
    "from_tensors_dataset2 = tf.data.Dataset.from_tensors(array2)\n",
    "print(from_tensors_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1367ea56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dde4af51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you can iterate through out your dataset\n",
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "1\n",
      "32\n",
      "24\n",
      "31\n",
      "you can use a numpy iterator\n",
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "1\n",
      "32\n",
      "24\n",
      "31\n",
      "you can select only a number of elements\n",
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"you can iterate through out your dataset\")\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())\n",
    "\n",
    "print(\"you can use a numpy iterator\")\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)\n",
    "\n",
    "print(\"you can select only a number of elements\")\n",
    "for sales in tf_dataset.take(3):\n",
    "    print(sales)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76ee89",
   "metadata": {},
   "source": [
    "## Filter values from your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0226239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter negative values\n",
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(24, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Filter negative values\")\n",
    "tf_dataset_non_negative = tf_dataset.filter(lambda x: x>0)\n",
    "for sales in tf_dataset_non_negative:\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f7f9a",
   "metadata": {},
   "source": [
    "# Map values from your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74628662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(420, shape=(), dtype=int32)\n",
      "tf.Tensor(440, shape=(), dtype=int32)\n",
      "tf.Tensor(620, shape=(), dtype=int32)\n",
      "tf.Tensor(20, shape=(), dtype=int32)\n",
      "tf.Tensor(640, shape=(), dtype=int32)\n",
      "tf.Tensor(480, shape=(), dtype=int32)\n",
      "tf.Tensor(620, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def currency_mx(input_val):\n",
    "    return input_val * 20\n",
    "\n",
    "tf_dataset_mx = tf_dataset_non_negative.map(currency_mx)\n",
    "for sales in tf_dataset_mx:\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06547cf8",
   "metadata": {},
   "source": [
    "# Shuffle\n",
    "how it works: https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d92bacc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(420, shape=(), dtype=int32)\n",
      "tf.Tensor(20, shape=(), dtype=int32)\n",
      "tf.Tensor(620, shape=(), dtype=int32)\n",
      "tf.Tensor(480, shape=(), dtype=int32)\n",
      "tf.Tensor(440, shape=(), dtype=int32)\n",
      "tf.Tensor(620, shape=(), dtype=int32)\n",
      "tf.Tensor(640, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf_dataset_shuffled = tf_dataset_mx.shuffle(3)\n",
    "for sales in tf_dataset_shuffled:\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c763e",
   "metadata": {},
   "source": [
    "# Batching\n",
    "Great for distributed environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f37e8d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[420 440 620]\n",
      "[ 20 640 480]\n",
      "[620]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset_batched = tf_dataset_mx.batch(3)\n",
    "for sales_batch in tf_dataset_batched:\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ae239",
   "metadata": {},
   "source": [
    "# Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ad22540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[420 620]\n",
      "[440  20]\n",
      "[480 640]\n",
      "[620]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset_processed = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset_processed = tf_dataset_processed.filter(lambda x: x>0).map(currency_mx).shuffle(2).batch(2)\n",
    "for sales in tf_dataset_processed:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318e9cd",
   "metadata": {},
   "source": [
    "# Prepare Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "844be3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'../datasets/pets/cat/cat_01.jpg'\n",
      "b'../datasets/pets/cat/cat_02.jpg'\n",
      "b'../datasets/pets/cat/cat_03.jpg'\n",
      "b'../datasets/pets/cat/cat_04.jpg'\n",
      "b'../datasets/pets/cat/cat_05.jpg'\n",
      "b'../datasets/pets/cat/cat_06.jpg'\n",
      "b'../datasets/pets/cat/cat_07.jpg'\n",
      "b'../datasets/pets/cat/cat_08.jpg'\n",
      "b'../datasets/pets/dog/dog_01.jpg'\n",
      "b'../datasets/pets/dog/dog_02.jpg'\n",
      "b'../datasets/pets/dog/dog_03.jpg'\n",
      "b'../datasets/pets/dog/dog_04.jpg'\n",
      "b'../datasets/pets/dog/dog_05.jpg'\n",
      "b'../datasets/pets/dog/dog_06.jpg'\n",
      "b'../datasets/pets/dog/dog_07.jpg'\n",
      "b'../datasets/pets/dog/dog_08.jpg'\n",
      "b'../datasets/pets/dog/dog_09.jpg'\n"
     ]
    }
   ],
   "source": [
    "# Create image dataet without shuffle\n",
    "image_ds = tf.data.Dataset.list_files(\"../datasets/pets/*/*.jpg\", shuffle=False)\n",
    "for file in image_ds.take(20):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed7c1f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'../datasets/pets/dog/dog_07.jpg'\n",
      "b'../datasets/pets/dog/dog_08.jpg'\n",
      "b'../datasets/pets/dog/dog_02.jpg'\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "image_ds = image_ds.shuffle(200)\n",
    "for file in image_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c443efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_count 17\n",
      "train_size 13\n",
      "size of training dataset:13, size of test dataset:4\n"
     ]
    }
   ],
   "source": [
    "# Now less divide\n",
    "class_names = [\"cat\", \"dog\"]\n",
    "image_count = len(image_ds)\n",
    "print(\"image_count\", image_count)\n",
    "\n",
    "# size of training dataset\n",
    "train_size = int(image_count * 0.8)\n",
    "print(\"train_size\", train_size)\n",
    "\n",
    "# Create the training dataset\n",
    "train_ds = image_ds.take(train_size)\n",
    "test_ds = image_ds.skip(train_size) #skip is the opposite of take\n",
    "\n",
    "print(f'size of training dataset:{len(train_ds)}, size of test dataset:{len(test_ds)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a85b8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'cat'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def get_label(path): #path is a tensor\n",
    "    return tf.strings.split(path, os.path.sep)[3]\n",
    "\n",
    "s='../datasets/pets/cat/Cat returns home after family believe they cremated.jpg'\n",
    "label = get_label(s)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0226f230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for item in train_ds.map(get_label):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1eff9a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: b'dog'\n",
      "image_shape: (825, 800, 3)\n",
      "label: b'dog'\n",
      "image_shape: (254, 380, 3)\n",
      "label: b'cat'\n",
      "image_shape: (280, 310, 3)\n",
      "label: b'cat'\n",
      "image_shape: (253, 380, 3)\n",
      "label: b'dog'\n",
      "image_shape: (1414, 2121, 3)\n",
      "label: b'cat'\n",
      "image_shape: (726, 982, 3)\n",
      "label: b'dog'\n",
      "image_shape: (1437, 2560, 3)\n",
      "label: b'dog'\n",
      "image_shape: (602, 1200, 3)\n",
      "label: b'cat'\n",
      "image_shape: (886, 1000, 3)\n",
      "label: b'cat'\n",
      "image_shape: (360, 640, 3)\n",
      "label: b'cat'\n",
      "image_shape: (216, 324, 3)\n",
      "label: b'dog'\n",
      "image_shape: (216, 324, 3)\n",
      "label: b'cat'\n",
      "image_shape: (1546, 1118, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def process_image(filepath):\n",
    "    label = get_label(filepath)\n",
    "    image = tf.io.read_file(filepath)\n",
    "    #decode jpg image\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    #resize\n",
    "    #mage = tf.image.resize(image, [128,128])\n",
    "    return image, label\n",
    "\n",
    "for (image, label) in train_ds.map(process_image):\n",
    "    print(f'label: {label}')\n",
    "    print(f'image_shape: {np.shape(image.numpy())}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b44df6",
   "metadata": {},
   "source": [
    "# Exercise with textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c083d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "texts_ds = tf.data.Dataset.list_files(\"../datasets/ex01/reviews/*/*.txt\")\n",
    "for text in texts_ds:\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df59f9b",
   "metadata": {},
   "source": [
    "# Filter -> remove empty text datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering has a problem: https://github.com/tensorflow/tensorflow/issues/46685\n",
    "# Basically you can't transform to numpy()\n",
    "def to_numpy(x):\n",
    "    print(x)\n",
    "    return x.numpy()\n",
    "\n",
    "# You can't do this\n",
    "#texts_ds = texts_ds.map(to_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_texts_dataset(filepath):    \n",
    "    # get label\n",
    "    label = tf.strings.split(filepath, os.path.sep)[4]\n",
    "    #read file\n",
    "    text = tf.io.read_file(filepath)    \n",
    "    return (label, text)\n",
    "\n",
    "# Extract: create labels and reviews\n",
    "reviews_labels_ds = texts_ds.map(process_texts_dataset)    \n",
    "for (label, review) in reviews_labels_ds:\n",
    "    print(f'label----->{label}, size: {len(review.numpy())}')\n",
    "\n",
    "print(\"AFTER FILTER\")\n",
    "# filter here\n",
    "reviews_labels_ds = reviews_labels_ds.filter(lambda label, review : review!='')\n",
    "for (label, review) in reviews_labels_ds:\n",
    "    print(f'label----->{label}, size: {len(review.numpy())}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
