{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Columns\n",
    "Tensorflow offers a Feature columns API, which is the way we can pre-process our incoming datasets to adopt the shape most appropiated for our model.\n",
    "- *One important factor to consider the usage of the feature_column API is that it is embeded in the model, so the feature engineering is easier to transport-export...*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "file_path = '../datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "# create dataset\n",
    "test_dataset = tf.data.experimental.make_csv_dataset(file_path, \n",
    "                                                    batch_size=5, \n",
    "                                                    label_name='AdoptionSpeed')\n",
    "#!head {file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Demo function\n",
    "## 1) Set a example features dictionary\n",
    "## 2) Define demo function, creates a FeatureLayer with a feature_column, then it will apply the transformations to a features dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'collections.OrderedDict'>\n",
      "Type                :[b'Cat' b'Cat' b'Cat' b'Cat' b'Dog']\n",
      "Age                 :[12 12 12  9 72]\n",
      "Breed1              :[b'Domestic Medium Hair' b'Domestic Short Hair' b'Domestic Short Hair'\n",
      " b'Domestic Short Hair' b'Terrier']\n",
      "Gender              :[b'Male' b'Female' b'Female' b'Male' b'Female']\n",
      "Color1              :[b'Brown' b'Black' b'Brown' b'Golden' b'Brown']\n",
      "Color2              :[b'No Color' b'Yellow' b'No Color' b'White' b'Cream']\n",
      "MaturitySize        :[b'Medium' b'Medium' b'Medium' b'Medium' b'Medium']\n",
      "FurLength           :[b'Medium' b'Short' b'Short' b'Short' b'Medium']\n",
      "Vaccinated          :[b'No' b'No' b'No' b'Yes' b'Yes']\n",
      "Sterilized          :[b'Yes' b'No' b'No' b'Yes' b'Yes']\n",
      "Health              :[b'Healthy' b'Healthy' b'Healthy' b'Healthy' b'Healthy']\n",
      "Fee                 :[0 0 0 0 0]\n",
      "Description         :[b'Hi, Any pet lover, nak donate seekor kucing kesayangan. Kesihatan memuaskan. Nak adopt coz bakal wife alah pada bulu kucing. So nk lepaskan kepada penjaga baru yg mmg menyayangi kucing. Sila hubungi saya utk set jumpa : tel : lokasi : presint 8, putrajaya'\n",
      " b'She is a stray cat, that came to feed regularly but being bullied a lot by other strays. So hopefully can get adopted coz she is soo manja and gentle. Adopter must be willing to neuter her and she will only go to a cage free home. Thank you.'\n",
      " b'She needs a loving and caring home..'\n",
      " b\"Ginger Boy was meant to be for trap-neuter-and-release. He has been treated for the flu, neutered, and given the 5-in-1 vaccination. We had to release him last week at the mamak restaurant where we found him, so that he doesn't lose his street survival skills and to make space for the next TNR cat, but he is an affectionate and playful sweetheart who deserves a good home. If you or anyone you know would like to adopt Ginger Boy, please please contact us! Ee Lynn: Aravind: Thank you!\"\n",
      " b'Hi... My name is \"kopi\", or at least that\\'s what this girl who found me yesterday noon decided to call me that when she found me nearby Bangsar TMC market, almost got bang by a car. I am lost. I don\\'t know what happened to my owners. There is no microchip or tag that shows my identity. And the vet says I\\'m diagnose breast cancer. However, I found donors to go for operation. I will be healthy again in no time. I am going to see if I can trace my owners. If I can\\'t find them, I need a new home. I am obedient, never bark so far, friendly and my temporary owner loves me. But she lives in a condo that has strict rules against pet in the building. I have been adopted by a good family now. My new owner is very lovely. I have all the attention and care to live well :D']\n",
      "PhotoAmt            :[3 1 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "# A example_batch is defined as the next element in the streaming of the dataset\n",
    "example_batch = next(iter(test_dataset))\n",
    "# extract the features and target_label\n",
    "features, target_label = example_batch\n",
    "# target label is a tensor\n",
    "print(type(target_label))\n",
    "# Features is an ordered dictionary\n",
    "print(type(features))\n",
    "for key, value in features.items():\n",
    "  print(\"{:20s}:{}\".format(key, value))\n",
    "\n",
    "# Demo function\n",
    "def demo(feature_column):\n",
    "  # Create a feature layer (a Dense Features Layer) with feature_column\n",
    "  feature_layer = layers.DenseFeatures(feature_column)\n",
    "  # Prints how the data looks like after the transformation\n",
    "  print(feature_layer(features).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Feature Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "photo_count = feature_column.numeric_column('PhotoAmt')\n",
    "demo(photo_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketized Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "age = feature_column.numeric_column('Age')\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[1,3,5])\n",
    "demo(age_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "animal_type = feature_column.categorical_column_with_vocabulary_list('Type', ['Cat','Dog'])\n",
    "animal_type_one_hot = feature_column.indicator_column(animal_type)\n",
    "demo(animal_type_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61609465 -0.0949748  -0.01655724  0.04095755  0.21639818  0.49341965\n",
      "   0.32157663 -0.1598886 ]\n",
      " [-0.25016016  0.25406116 -0.5464453  -0.00214967  0.4917772   0.25983012\n",
      "  -0.09460129  0.54370815]\n",
      " [-0.25016016  0.25406116 -0.5464453  -0.00214967  0.4917772   0.25983012\n",
      "  -0.09460129  0.54370815]\n",
      " [-0.25016016  0.25406116 -0.5464453  -0.00214967  0.4917772   0.25983012\n",
      "  -0.09460129  0.54370815]\n",
      " [-0.19106169  0.03029988  0.02132679  0.08476277 -0.13910243  0.3972798\n",
      "   0.3305021  -0.26949188]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all values of Breed1 column with a panda dataframe\n",
    "breed_df = pd.read_csv(file_path, usecols=['Breed1'])\n",
    "breed_unique = breed_df['Breed1'].unique()\n",
    "    \n",
    "breed1 = feature_column.categorical_column_with_vocabulary_list('Breed1', breed_unique)\n",
    "breed1_embedding = feature_column.embedding_column(breed1, dimension=8)\n",
    "demo(breed1_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashed feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "breed1_hashed = feature_column.categorical_column_with_hash_bucket('Breed1',\n",
    "     hash_bucket_size=10)\n",
    "demo(feature_column.indicator_column(breed1_hashed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossed feature columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "crossed_feature = feature_column.crossed_column([age_buckets, animal_type], hash_bucket_size=10)\n",
    "demo(feature_column.indicator_column(crossed_feature))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
